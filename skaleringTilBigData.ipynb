{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyspark as spark\n",
    "#import findspark\n",
    "#import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a schema for the data uing af Struct type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([ \n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Month\", IntegerType(), True),\n",
    "    StructField(\"DayofMonth\", IntegerType(), True),\n",
    "    StructField(\"DayOfWeek\", IntegerType(), True),\n",
    "    StructField(\"DepTime\", IntegerType(), True),\n",
    "    StructField(\"CRSDepTime\", IntegerType(), True),\n",
    "    StructField(\"ArrTime\", IntegerType(), True),\n",
    "    StructField(\"CRSArrTime\", IntegerType(), True),\n",
    "    StructField(\"UniqueCarrier\", StringType(), True),\n",
    "    StructField(\"FlightNum\", IntegerType(), True),\n",
    "    StructField(\"TailNum\", StringType(), True),\n",
    "    StructField(\"ActualElapsedTime\", IntegerType(), True),\n",
    "    StructField(\"CRSElapsedTime\", IntegerType(), True),\n",
    "    StructField(\"AirTime\", IntegerType(), True),\n",
    "    StructField(\"ArrDelay\", IntegerType(), True),\n",
    "    StructField(\"DepDelay\", IntegerType(), True),\n",
    "    StructField(\"Origin\", StringType(), True),\n",
    "    StructField(\"Dest\", StringType(), True),\n",
    "    StructField(\"Distance\", IntegerType(), True),\n",
    "    StructField(\"TaxiIn\", IntegerType(), True),\n",
    "    StructField(\"TaxiOut\", IntegerType(), True),\n",
    "    StructField(\"Cancelled\", IntegerType(), True),\n",
    "    StructField(\"CancellationCode\", StringType(), True),\n",
    "    StructField(\"Diverted\", IntegerType(), True),\n",
    "    StructField(\"CarrierDelay\", IntegerType(), True),\n",
    "    StructField(\"WeatherDelay\", IntegerType(), True),\n",
    "    StructField(\"NASDelay\", IntegerType(), True),\n",
    "    StructField(\"SecurityDelay\", IntegerType(), True),\n",
    "    StructField(\"LateAircraftDelay\", IntegerType(), True)])\n",
    "flights = spark.read.csv(\"./data/2008.csv\",header=True,schema=schema, nullValue='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the number of flights from JFK to LAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8078"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.where((col('Origin') == 'JFK') & (col('Dest') == 'LAX')).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the sum and average of all arrival delays for all delayed flights\n",
    "Average could be found using \"Describe\", but to include sum, we will use select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|   avg(ArrDelay)|sum(ArrDelay)|\n",
      "+----------------+-------------+\n",
      "|8.16845238729114|     55994978|\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.describe('ArrDelay').show()\n",
    "flights.select(avg('ArrDelay'), sum('ArrDelay')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the average departure delay for each state.\n",
    "To do this, we need the airport data from airports.csv. Instead of defining the schema explicitely as above, for illustration purposes, we´ll just \"infer\" the schema, which means asking Spark to figure it out by presampling rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----------+-----+-------+-----------+------------+\n",
      "|iata|             airport|       city|state|country|        lat|        long|\n",
      "+----+--------------------+-----------+-----+-------+-----------+------------+\n",
      "| 00M|            Thigpen |Bay Springs|   MS|    USA|31.95376472|-89.23450472|\n",
      "| 00R|Livingston Municipal| Livingston|   TX|    USA|30.68586111|-95.01792778|\n",
      "+----+--------------------+-----------+-----+-------+-----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports = spark.read.csv(\"./data/airports.csv\",header=True,inferSchema=True, nullValue='NA')\n",
    "airports.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets join the dataframes, group the result on states and calculate the average departure-delay- To illustrate the \"agg\" function used with a map, we´ll add the average arrival-delays aswell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-------------------+\n",
      "|state|     avg(DepDelay)|      avg(ArrDelay)|\n",
      "+-----+------------------+-------------------+\n",
      "|   AZ| 7.821406634575592| 4.2603182919641105|\n",
      "|   SC|10.073743016759776|  8.942515845928815|\n",
      "|   LA|  8.75001528397628|  8.065231382163653|\n",
      "|   MN| 7.420257912196289| 7.5076487421901925|\n",
      "|   NJ| 18.28530315230682| 17.073619219183303|\n",
      "|   OR| 6.988035144205845|  3.913974378255698|\n",
      "|   VA| 9.741461461852408|  9.015987468487651|\n",
      "| null| 6.630157701447397|  5.631909820073704|\n",
      "|   RI|10.345095558668053|  7.284535521603119|\n",
      "|   KY| 9.408317082603078|  8.848705808601547|\n",
      "|   WY| 4.837221577113903|  4.455306079220504|\n",
      "|   NH|10.483407140123559|  7.463268777088934|\n",
      "|   MI| 8.959508598521376|  9.411726489355809|\n",
      "|   NV|10.047854928293972|  5.234664517182271|\n",
      "|   WI| 9.898691052537206| 10.273451327433628|\n",
      "|   ID| 4.312914217246415|  1.876640912159628|\n",
      "|   CA| 8.567509354076408|  5.481386483085351|\n",
      "|   NE| 8.982463876263482|  7.693161316676312|\n",
      "|   CT|7.5934458031662455| 5.9831527025149365|\n",
      "|   MT|1.4785465405674465|0.19802178039764212|\n",
      "+-----+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.join(airports, flights.Origin == airports.iata).groupBy(airports.state)\\\n",
    ".agg({\"DepDelay\": \"avg\", \"ArrDelay\": \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
